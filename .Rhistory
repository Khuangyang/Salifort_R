roc_object <- roc(predictor = rf_predict[,2], response = test$left)
auc(test$left, rf_predict)
rf_auc <- auc(test$left, rf_predict)
rf_auc
install.packages('ISLR')
install.packages('rpart.plot')
library(ISLR)
library(rpart)
library(rpart.plot)
fit <- rpart(left~., data = train, method = 'class')
rpart.plot(fit, extra = 106)
tree_predict <-predict(fit, test, type = 'class')
tree_predict <-predict(fit, test, type = 'response')
tree_predict <-predict(fit, test, type = 'prob')
library(pROC)
tree_auc <- auc(test$left, tree_predict)
tree_auc <- auc(test$left, as.numberic(tree_predict))
library(tidyverse)
library(data.table)
library(dplyr)
tree_auc <- auc(test$left, as.numberic(tree_predict))
tree_auc <- auc(test$left, as.numeric(tree_predict))
tree_predict
tree_auc <- auc(test$left, tree_predict[,2])
tree_auc
rf_auc
cm_tree <- confusionMatrix(test$left,tree_predict, mode = "everything")
library(e1071)
cm_tree <- confusionMatrix(test$left,tree_predict, mode = "everything")
library(caret)
library(e1071)
cm_tree <- confusionMatrix(test$left,tree_predict, mode = "everything")
cm_tree <- confusionMatrix(as.factor(test$left),tree_predict, mode = "everything")
str(test)
cm_tree <- confusionMatrix(test$left,tree_predict[,2], mode = "everything")
test$left = ifelse(tree_predict > 0.5, "1", "0")
test$left = as.factor(test$left)
cm_tree <- confusionMatrix(test$left,tree_predict, mode = "everything")
View(test)
indexset <- createDataPartition(df_logreg$left,p = 0.75,list = F)
train <- df_logreg[indexset,]
test <- df_logreg[-indexset,]
View(test)
tree_prob <-predict(fit, test, type = 'prob')
tree_auc <- auc(test$left, tree_prob[,2])
tree_auc
tree_predict <- predict(fit,test,type='class')
cm_tree <- confusionMatrix(test$left,tree_predict, mode = "everything")
cm_tree <- confusionMatrix(as.factor(test$left),tree_predict, mode = "everything")
cm_tree
control <- rpart.control(minsplit = 2,
minbucket = round(6 / 3),
maxdepth = 4,
cp = 0)
tune_fit <- rpart(left~., data = train, method="class", control = control)
tree_predict2 <-predict(tune_fit, test, type = 'class')
cm_tree2 <- confusionMatrix(as.factor(test$left),tree_predict2, mode = "everything")
cm_tree2
tree_prob2 <-predict(fit, test, type = 'prob')
tree_auc2 <- auc(test$left, tree_prob2[,2])
tree_auc
tree_auc2
tree_prob2 <-predict(tune_fit, test, type = 'prob')
tree_auc2 <- auc(test$left, tree_prob2[,2])
tree_auc2
source("~/salifort/salifort.R")
save.image("~/salifort/salifort_env.RData")
tree_auc2
rf_auc
df3 <- df_enco
df3 <- df3 %>% mutate(overworked = df3$average_monthly_hours)
View(df3)
df3$average_monthly_hours <- null
df3$average_monthly_hours <- NULL
View(df3)
str(df3)
df3$satisfaction_level<- NULL
df3$overworked <- ifelse(df3$overworked>175,1,0)
View(df2)
indexset2 <- createDataPartition(df3$left,p = 0.75,list = F)
train2 <- df3[indexset,]
test2 <- df3[-indexset,]
tune_fit2 <- rpart(left~., data = train2, method="class", control = control)
tree_predict3 <-predict(tune_fit2, test, type = 'class')
tree_predict3 <-predict(tune_fit2, test2, type = 'class')
cm_tree3 <- confusionMatrix(as.factor(test$left),tree_predict3, mode = "everything")
cm_tree3 <- confusionMatrix(as.factor(test2$left),tree_predict3, mode = "everything")
tree_prob3 <-predict(tune_fit2, test2, type = 'prob')
tree_auc3 <- auc(test2$left, tree_prob3[,2])
tree_auc3
rf2 <- randomForest(formula = left ~ ., data = train2, metric="ROC", importance=TRUE)
library(randomForest)
rf2 <- randomForest(formula = left ~ ., data = train2, metric="ROC", importance=TRUE)
print(rf2)
print(rf)
rf2_predict <-predict(rf2, test2, type="response")
install.packages("pROC")
library(pROC)
rf2_auc <- auc(test2$left, rf2_predict)
tree_auc3
rf2_auc
cm_rf2 <- confusionMatrix(as.factor(test2$left),rf2_predict, mode='everything')
library(caret)
library(e1071)
cm_rf2 <- confusionMatrix(as.factor(test2$left),rf2_predict, mode='everything')
cm_rf2 <- confusionMatrix(test2$left,rf2_predict, mode='everything')
cm_rf2 <- confusionMatrix(test2$left,as.factor(rf2_predict), mode='everything')
rf2_cm_table <- table(test$left, rf2_predict)
rf2_cm_table <- table(test2$left, rf2_predict)
cm_rf2 <- confusionMatrix(rf2_cm_table, mode='everything')
rf2_cm_table
rf_prob_table2 <- table(test2$left, rf2_predict)
rm(rf2_cm_table)
cm_rf <- confusionMatrix(rf_prob_table2, mode='everything')
rf <- randomForest(formula = left ~ ., data = train, metric="ROC", importance=TRUE)
library(randomForest)
rf <- randomForest(formula = left ~ ., data = train, metric="ROC", importance=TRUE)
print(rf)
rf_predict <-predict(rf, test, type="response")
install.packages("pROC")
library(pROC)
rf_auc <- auc(test$left, rf_predict)
rf_prob_table <- table(test$left, rf_predict)
cm_rf <- confusionMatrix(rf_prob_table, mode='everything')
rf_predict <-predict(rf, test, type="response")
rf <- randomForest(formula = left ~ ., data = train, metric="ROC", importance=TRUE)
library(randomForest)
rf <- randomForest(formula = left ~ ., data = train, metric="ROC", importance=TRUE)
print(rf)
rf_predict <-predict(rf, test, type="response")
library(pROC)
rf_auc <- auc(test$left, rf_predict)
rf_auc
rf_prob_table <- table(test$left, rf_predict)
cm_rf <- confusionMatrix(rf_prob_table, mode='everything')
library(caret)
cm_rf <- confusionMatrix(rf_prob_table, mode='everything')
cm_rf <- confusionMatrix(test$left,rf_predict, mode='everything')
cm_rf <- confusionMatrix(as.factor(test$left),rf_predict, mode='everything')
cm_rf <- confusionMatrix(as.factor(test$left),as.factor(rf_predict), mode='everything')
rf_prob_table
cm_rf <- confusionMatrix(test$left,rf_predict[,2], mode='everything')
rf_prob_table <- table(test$left, rf_predict[,2])
cm_rf <- confusionMatrix(rf_prob_table, mode='everything')
str(test)
train$left <- as.factor(train$left)
rf <- randomForest(formula = left ~ ., data = train, metric="ROC", importance=TRUE)
print(rf)
rf_predict <-predict(rf, test, type="response")
rf_predict
rf_prob_table <- table(test$left, rf_predict)
cm_rf <- confusionMatrix(rf_prob_table, mode='everything')
cm_rf
rf_auc <- auc(test$left, rf_predict)
rf_auc
set.seed(42)
indexset2 <- createDataPartition(df3$left,p = 0.75,list = F)
train2 <- df3[indexset,]
test2 <- df3[-indexset,]
train2$left <- as.factor(train2$left)
rf2 <- randomForest(formula = left ~ ., data = train2, metric="ROC", importance=TRUE)
print(rf2)
rf2_predict <-predict(rf2, test2, type="response")
rf_prob_table2 <- table(test2$left, rf2_predict)
cm_rf2 <- confusionMatrix(rf_prob_table2, mode='everything')
cm_rf2
rf2_auc <- auc(test2$left, rf2_predict)
rf2_auc
tree_auc3
rf_auc
cm_rf2
indexset2 <- createDataPartition(df3$left,p = 0.75,list = F)
train2 <- df3[indexset2,]
test2 <- df3[-indexset2,]
tune_fit2 <- rpart(left~., data = train2, method="class", control = control)
set.seed(42)
indexset2 <- createDataPartition(df3$left,p = 0.75,list = F)
train2 <- df3[indexset2,]
test2 <- df3[-indexset2,]
library(ISLR)
library(rpart)
library(rpart.plot)
tune_fit2 <- rpart(left~., data = train2, method="class", control = control)
tree_predict3 <-predict(tune_fit2, test2, type = 'class')
cm_tree3 <- confusionMatrix(as.factor(test2$left),tree_predict3, mode = "everything")
tree_prob3 <-predict(tune_fit2, test2, type = 'prob')
tree_auc3 <- auc(test2$left, tree_prob3[,2])
train2$left <- as.factor(train2$left)
rf2 <- randomForest(formula = left ~ ., data = train2, metric="ROC", importance=TRUE)
print(rf2)
rf2_predict <-predict(rf2, test2, type="response")
install.packages("pROC")
library(pROC)
rf2_auc <- auc(test2$left, rf2_predict)
install.packages("pROC")
rf2_auc <- auc(test2$left, rf2_predict)
rf_prob_table2 <- table(test2$left, rf2_predict)
cm_rf2 <- confusionMatrix(rf_prob_table2, mode='everything')
rf2_auc
tree_auc3
cm_rf2
save.image("~/salifort/salifort_env.RData")
rpart.plot(tune_fit2, extra = 106)
install.packages("vip")
library(vip)
vi_tree <- tune_fit2$variable.importance
vi_rf <- rf2$variable.importance
vi_tree
vi_rf
vi_rf <- rf2$variable.importance
rf2 <- randomForest(formula = left ~ ., data = train2, metric="ROC", importance=TRUE)
vi_rf <- rf2$variable.importance
varImp(rf2)
vi_tree <- varImp(tune_fit2)
vi_rf <- varImp(rf2)
View(vi_tree)
View(vi_rf)
View(rf2)
View(tune_fit2)
rf2[["importance"]]
rf2[["importanceSD"]]
importance(rf2)
varImpPlot(rf2, sort=FALSE,main="Variable Importance Plot")
rm(vi_rf)
plot(varImp(tune_fit2))
View(vi_tree)
plot(vi_tree)
vip(tune_fit2)
save.image("~/salifort/salifort_env.RData")
source("~/salifort/salifort.R")
vip(rf2)
source("~/salifort/salifort.R")
View(df)
df <- read.csv("HR_capstone_dataset", header = TRUE)
df <- read.csv("C:\Users\khuan\Downloads\salifort capstone\HR_capstone_dataset.csv", header = TRUE)
df <- read.csv("C:/Users/khuan/Downloads/salifort capstone/HR_capstone_dataset.csv", header = TRUE)
View(df)
summary(df)
colnames(df)
library(tidyverse)
library(psych)
library(data.table)
# rename col names
setnames(df,  old=c("average_montly_hours"), new=c("average_monthly_hours"))
setnames(df,  old=c("time_spend_company"), new=c("tenure"))
# rename col names
setnames(df,  old=c("average_montly_hours"), new=c("average_monthly_hours"))
# determine NA
sum(is.na(df))
# determine duplicated
sum(duplicated(df))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
df <- read.csv("C:/Users/khuan/Downloads/salifort capstone/HR_capstone_dataset.csv", header = TRUE)
# Chunk 3
colnames(df)
# Chunk 4
library(tidyverse)
library(psych)
library(data.table)
View(df_duplicated)
# filter out duplicated col and evaluated it
df_duplicated <- df %>% mutate(duplicate = duplicated(df))
df_duplicated <- df_duplicated %>% filter(duplicate=='TRUE')
df_duplicated <- sort_by(df_duplicated, list(df_duplicated$satisfaction_level,df_duplicated$last_evaluation,df_duplicated$number_project,df_duplicated$average_monthly_hours,df_duplicated$tenure,df_duplicated$work_accident,df_duplicated$work_accident,df_duplicated$left,df_duplicated$promotion_last_5years,df_duplicated$department,df_duplicated$salary))
# filter out duplicated col and evaluated it
df_duplicated <- df %>% mutate(duplicate = duplicated(df))
df_duplicated <- df_duplicated %>% filter(duplicate=='TRUE')
df_duplicated <- sort_by(df_duplicated, list(df_duplicated$satisfaction_level,df_duplicated$last_evaluation,df_duplicated$number_project,df_duplicated$average_monthly_hours,df_duplicated$tenure,df_duplicated$work_accident,df_duplicated$work_accident,df_duplicated$left,df_duplicated$promotion_last_5years,df_duplicated$department,df_duplicated$salary))
# filter out duplicated col and evaluated it
df_duplicated <- df %>% mutate(duplicate = duplicated(df))
df_duplicated <- df_duplicated %>% filter(duplicate=='TRUE')
df_duplicated <- sort_by(df_duplicated, list(df_duplicated$satisfaction_level,df_duplicated$last_evaluation,df_duplicated$number_project,df_duplicated$average_monthly_hours,df_duplicated$tenure,df_duplicated$work_accident,df_duplicated$work_accident,df_duplicated$left,df_duplicated$promotion_last_5years,df_duplicated$department,df_duplicated$salary))
# remove duplicated
df1 <- distinct(df)
# remove duplicated
df1 <- distinct(df)
# confirm no duplicated
sum(duplicated(df1))
# plot tenure boxplot
boxplot(df1$tenure)
# determine upper & lower limit
q1 <- quantile(df1$tenure,probs = 0.25)
q3 <- quantile(df1$tenure,probs = 0.75)
iqr <- q3-q1
upper_limit <- q3+(iqr*1.5)
lower_limit <- q1-(iqr*1.5)
print("upper : upper_limit")
print("upper" : upper_limit)
"upper" upper_limit
# determine upper & lower limit
q1 <- quantile(df1$tenure,probs = 0.25)
q3 <- quantile(df1$tenure,probs = 0.75)
iqr <- q3-q1
upper_limit <- q3+(iqr*1.5)
lower_limit <- q1-(iqr*1.5)
print(upper_limit)
print(lower_limit)
upper_limit
# draw left table
df_left <- table(df1$left)
df_left <- data.frame(df_left)
df_left <- df_left %>% mutate(percent = Freq/sum(Freq))
df_left
# boxplot hours vs projects (left)
ggplot() + geom_boxplot(data= df1, mapping= aes(x=as.character(number_project), y=average_monthly_hours,fill=as.factor(left))) +
labs(title="hours vs project", x="project", y="hours")+ scale_fill_manual('0:stayed\n1:quit', values=c('blue','pink'))
# barplot : projects vs left
ggplot() + geom_bar(position='dodge',data= df1, mapping= aes(x=number_project, fill = as.factor(left)))+
labs(title="project vs left", x="project", y="count")+scale_fill_manual('0:stayed\n1:quit', values=c('blue','pink'))
# scatterplot : hours vs sat_level (left)
scatter1 <- ggplot(df1, aes(x = average_monthly_hours, y = satisfaction_level)) +
geom_point(aes(color = as.factor(left)),alpha=0.3)+scale_color_manual('0:stayed\n1:quit', values=c('green','red'))+
geom_vline(xintercept=166.67, linetype='dashed', color='blue', linewidth=2)
scatter2 <- ggplot(df1, aes(x = average_monthly_hours, y = last_evaluation)) +
geom_point(aes(color = as.factor(left)),alpha=0.3)+scale_color_manual('0:stayed\n1:quit', values=c('green','red'))+
geom_vline(xintercept=166.67, linetype='dashed', color='blue', linewidth=2)
# scatterplot : hours vs eval (left)
scatter2 <- ggplot(df1, aes(x = average_monthly_hours, y = last_evaluation)) +
geom_point(aes(color = as.factor(left)),alpha=0.3)+scale_color_manual('0:stayed\n1:quit', values=c('green','red'))+
geom_vline(xintercept=166.67, linetype='dashed', color='blue', linewidth=2)
scatter2
scatter2 <- ggplot(df1, aes(x = average_monthly_hours, y = last_evaluation)) +
geom_point(aes(color = as.factor(left)),alpha=0.3)+scale_color_manual('0:stayed\n1:quit', values=c('green','red'))+
geom_vline(xintercept=166.67, linetype='dashed', color='blue', linewidth=2)
# creating correlation matrix
corr_mat <- round(cor(df2),3)
melted_corr_mat <- melt(corr_mat)
ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value, colour = 'red')) +
geom_tile() + geom_text(aes(Var2, Var1, label = value),
color = "red", size = 4)
# creating correlation matrix
corr_mat <- round(cor(df2),3)
melted_corr_mat <- melt(corr_mat)
heatmap2 <- ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value, colour = 'red')) +
geom_tile() + geom_text(aes(Var2, Var1, label = value),
color = "red", size = 4)
corr_mat <- round(cor(df2),3)
melted_corr_mat <- melt(corr_mat)
heatmap2 <- ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value, colour = 'red')) +
geom_tile() + geom_text(aes(Var2, Var1, label = value),
color = "red", size = 4)
# creating correlation matrix
corr_mat <- round(cor(df2),3)
melted_corr_mat <- melt(corr_mat)
heatmap2 <- ggplot(data = melted_corr_mat, aes(x=Var1, y=Var2, fill=value, colour = 'red')) +
geom_tile() + geom_text(aes(Var2, Var1, label = value),
color = "red", size = 4)
heatmap2
model
?rpart
?randomforest
??randomforest
?rfcv
library(randomForest)
?rfcv()
rfcv <- rfcv(train,train$left,cv.fold=4)
rfcv
print(rfcv)
summary(rfcv)
with(rfcv, plot(n.var, error.cv, log="x", type="o", lwd=2))
?train
?expand.grid
modelLookup('rf')
?tuneRF
set.seed(42)
## Define repeated cross validation with 4 folds and three repeats
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4)
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4)
library(caret)
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4)
set.seed(42)
train_index <- createDataPartition(y=df_logreg$left, p=0.75, list=FALSE)
#
training_set <- df_logreg[train_index, ]
testing_set <- df_logreg[-train_index, ]
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
training_set$left <- as.factor(training_set$left)
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4,classProbs=TRUE)
set.seed(42)
train_index <- createDataPartition(y=df_logreg$left, p=0.75, list=FALSE)
## Subset the data
training_set <- df_logreg[train_index, ]
testing_set <- df_logreg[-train_index, ]
training_set$left <- as.factor(training_set$left)
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
forest$finalModel
training_set$left <- as.factor(training_set$left)
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
h
str(training_set)
train_index <- createDataPartition(y=df_logreg$left, p=0.75, list=FALSE)
## Subset the data
training_set <- df_logreg[train_index, ]
testing_set <- df_logreg[-train_index, ]
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
training_set$left <- as.factor(training_set$left)
forest <- train(left~., data=training_set, method='rf', trControl=repeat_cv,
metric='ROC')
make.names
train_index <- createDataPartition(y=df_logreg$left, p=0.75, list=FALSE)
## Subset the data
training_set <- df_logreg[train_index, ]
testing_set <- df_logreg[-train_index, ]
training_set$left <- factor(training_set$left)
forest <- train(left~.,
data=training_set,
method='rf',
trControl=repeat_cv,
metric='ROC')
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4,classProbs=F)
train_index <- createDataPartition(y=df_logreg$left, p=0.75, list=FALSE)
## Subset the data
training_set <- df_logreg[train_index, ]
testing_set <- df_logreg[-train_index, ]
forest <- train(left~.,
data=training_set,
method='rf',
trControl=repeat_cv,
metric='ROC')
training_set$left <- as.factor(training_set$left)
forest <- train(left~.,
data=training_set,
method='rf',
trControl=repeat_cv,
metric='ROC')
forest$finalModel
repeat_cv <- trainControl(method='repeatedcv', number=4, repeats=4,classProbs=T)
forest <- train(left~.,
data=training_set,
method='rf',
trControl=repeat_cv,
metric='ROC')
make.names(X0,X1)
make.names()
make.names(c("0", "1"))
str(training_set)
training_set$left <- ifelse(training_set$left=="1","yes","no")
str(training_set)
forest <- train(left~.,
data=training_set,
method='rf',
trControl=repeat_cv,
metric='ROC')
forest$finalModel
auc(testing_set$left,forest)
library(pROC)
auc(testing_set$left,forest)
forest_prob <- predict(forest, testing_set, type = "prob")
head(forest_prob)
roc(testing_set$left,forest_prob[,2])
confusionMatrix(forest_prob)
confusionMatrix(forest_prob,mode='everything')
View(testing_set)
y_hats <- predict(object=forest,  newdata=testing_set[, -7])
head(y_hats)
y_hats
confusionMatrix(y_hats)
confusionMatrix(testing_set$left,y_hats)
confusionMatrix(as.factor(testing_set$left),y_hats)
str(testing_set)
confusionMatrix(testing_set$left,as.factor(y_hats))
y_hats
str(y_hats)
testing_set$left <- ifelse(testing_set$left=="1","yes","no")
str(testing_set)
confusionMatrix(testing_set$left,y_hats)
y_hats
confusionMatrix(as.factor(testing_set$left),y_hats)
str(y_hats)
str(as.factor(testing_set$left))
confusionMatrix(as.factor(testing_set$left),y_hats,mode='everything')
vip(forest)
library(vip)
vip(forest)
roc(testing_set$left,forest_prob[,2])
vip(rf2)
set.seed(42)
## Split the data so that we use 75% of it for training
train_index2 <- createDataPartition(y=df3$left, p=0.75, list=FALSE)
repeat_cv <- trainControl(method='repeatedcv', number=4,repeats=4,classProbs=T)
training_set2 <- df3[train_index2, ]
testing_set2 <- df3[-train_index2, ]
training_set2$left <- as.factor(training_set2$left)
training_set2$left <- ifelse(training_set2$left=="1","yes","no")
forest2 <- train(left~.,
data=training_set2,
method='rf',
trControl=repeat_cv,
metric='AUC')
forest2$finalModel
forest_prob2 <- predict(forest2, testing_set2, type = "prob")
head(forest_prob2)
forest_auc2 <- auc(testing_set2$left,forest_prob2[,2])
forest_auc2
str(testing_set2)
View(testing_set2)
y_hats2 <- predict(object=forest2,  newdata=testing_set2[, -5])
head(y_hats2)
testing_set2$left <- ifelse(testing_set2$left=="1","yes","no")
forest_cm2 <- confusionMatrix(as.factor(testing_set2$left),y_hats,mode='everything')
forest_cm2 <- confusionMatrix(as.factor(testing_set2$left),y_hats2,mode='everything')
forest_cm2
View(forest_cm2)
source("~/salifort/salifort.R")
